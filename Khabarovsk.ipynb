{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOLO-POSE VISUALIZATION "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ultralytics import YOLO\n",
    "\n",
    "# model = YOLO('yolov8s-pose.pt')\n",
    "\n",
    "# folder_with_mp4 = \"Анализ бригад (телефон)/Есть телефон\"\n",
    "\n",
    "# results = model(source=\"Анализ бригад (телефон)/Есть телефон/00_51_01.mp4\", show=True, vid_stride=1, iou=0.6, conf=0.3, nms=True, device='cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ULTRA FAST YOLO-POSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 persons, 31.2ms\n",
      "Speed: 1.7ms preprocess, 31.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 30.3ms\n",
      "Speed: 2.1ms preprocess, 30.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 30.9ms\n",
      "Speed: 2.5ms preprocess, 30.9ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 28.9ms\n",
      "Speed: 2.1ms preprocess, 28.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 28.8ms\n",
      "Speed: 2.2ms preprocess, 28.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 26.5ms\n",
      "Speed: 3.0ms preprocess, 26.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.3ms\n",
      "Speed: 2.8ms preprocess, 25.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.3ms\n",
      "Speed: 2.1ms preprocess, 25.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 24.7ms\n",
      "Speed: 2.2ms preprocess, 24.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.0ms\n",
      "Speed: 2.9ms preprocess, 25.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 24.9ms\n",
      "Speed: 2.1ms preprocess, 24.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 24.8ms\n",
      "Speed: 2.2ms preprocess, 24.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.2ms\n",
      "Speed: 1.8ms preprocess, 25.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 24.9ms\n",
      "Speed: 2.0ms preprocess, 24.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 24.8ms\n",
      "Speed: 2.2ms preprocess, 24.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 24.6ms\n",
      "Speed: 1.9ms preprocess, 24.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 24.8ms\n",
      "Speed: 2.0ms preprocess, 24.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 24.9ms\n",
      "Speed: 2.2ms preprocess, 24.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.3ms\n",
      "Speed: 1.9ms preprocess, 25.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 24.7ms\n",
      "Speed: 2.3ms preprocess, 24.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 24.8ms\n",
      "Speed: 2.1ms preprocess, 24.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.9ms\n",
      "Speed: 2.1ms preprocess, 25.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.9ms\n",
      "Speed: 1.9ms preprocess, 25.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 26.0ms\n",
      "Speed: 2.1ms preprocess, 26.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.7ms\n",
      "Speed: 2.0ms preprocess, 25.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Отвлечение на кадре_00:24\n",
      "Отвлечение на кадре_00:25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 2 persons, 25.4ms\n",
      "Speed: 2.1ms preprocess, 25.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 26.2ms\n",
      "Speed: 2.1ms preprocess, 26.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Отвлечение на кадре_00:26\n",
      "Отвлечение на кадре_00:27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 2 persons, 26.5ms\n",
      "Speed: 2.0ms preprocess, 26.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 27.0ms\n",
      "Speed: 2.5ms preprocess, 27.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Отвлечение на кадре_00:28\n",
      "Отвлечение на кадре_00:29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 2 persons, 26.5ms\n",
      "Speed: 2.2ms preprocess, 26.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.6ms\n",
      "Speed: 2.3ms preprocess, 25.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Отвлечение на кадре_00:30\n",
      "Отвлечение на кадре_00:31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 2 persons, 26.3ms\n",
      "Speed: 1.9ms preprocess, 26.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 24.8ms\n",
      "Speed: 1.9ms preprocess, 24.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 24.8ms\n",
      "Speed: 1.7ms preprocess, 24.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Отвлечение на кадре_00:32\n",
      "Отвлечение на кадре_00:33\n",
      "Отвлечение на кадре_00:34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 persons, 24.5ms\n",
      "Speed: 1.9ms preprocess, 24.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.5ms\n",
      "Speed: 2.1ms preprocess, 25.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 24.9ms\n",
      "Speed: 3.0ms preprocess, 24.9ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Отвлечение на кадре_00:35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 persons, 25.9ms\n",
      "Speed: 2.3ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.1ms\n",
      "Speed: 2.0ms preprocess, 25.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 24.5ms\n",
      "Speed: 1.8ms preprocess, 24.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.5ms\n",
      "Speed: 2.4ms preprocess, 25.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 24.9ms\n",
      "Speed: 2.0ms preprocess, 24.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 24.6ms\n",
      "Speed: 1.9ms preprocess, 24.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.4ms\n",
      "Speed: 1.7ms preprocess, 25.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.0ms\n",
      "Speed: 1.8ms preprocess, 25.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.5ms\n",
      "Speed: 2.4ms preprocess, 25.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.6ms\n",
      "Speed: 1.9ms preprocess, 25.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 26.0ms\n",
      "Speed: 2.0ms preprocess, 26.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.2ms\n",
      "Speed: 2.3ms preprocess, 25.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.4ms\n",
      "Speed: 2.1ms preprocess, 25.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 26.2ms\n",
      "Speed: 1.7ms preprocess, 26.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.9ms\n",
      "Speed: 2.3ms preprocess, 25.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 26.2ms\n",
      "Speed: 2.5ms preprocess, 26.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.4ms\n",
      "Speed: 2.2ms preprocess, 25.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.4ms\n",
      "Speed: 2.0ms preprocess, 25.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 26.0ms\n",
      "Speed: 2.2ms preprocess, 26.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 26.1ms\n",
      "Speed: 2.2ms preprocess, 26.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 26.4ms\n",
      "Speed: 2.0ms preprocess, 26.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 26.0ms\n",
      "Speed: 2.5ms preprocess, 26.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 26.1ms\n",
      "Speed: 2.6ms preprocess, 26.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 26.2ms\n",
      "Speed: 2.4ms preprocess, 26.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 24.8ms\n",
      "Speed: 2.0ms preprocess, 24.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.2ms\n",
      "Speed: 1.9ms preprocess, 25.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 25.1ms\n",
      "Speed: 1.9ms preprocess, 25.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 24.8ms\n",
      "Speed: 2.1ms preprocess, 24.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 24.7ms\n",
      "Speed: 1.8ms preprocess, 24.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.7ms\n",
      "Speed: 2.1ms preprocess, 25.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 24.9ms\n",
      "Speed: 2.2ms preprocess, 24.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 24.6ms\n",
      "Speed: 2.1ms preprocess, 24.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 24.9ms\n",
      "Speed: 1.9ms preprocess, 24.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.0ms\n",
      "Speed: 2.0ms preprocess, 25.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 24.9ms\n",
      "Speed: 1.9ms preprocess, 24.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 24.6ms\n",
      "Speed: 1.8ms preprocess, 24.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 24.7ms\n",
      "Speed: 1.9ms preprocess, 24.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 26.6ms\n",
      "Speed: 1.7ms preprocess, 26.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.2ms\n",
      "Speed: 2.7ms preprocess, 25.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 24.9ms\n",
      "Speed: 2.9ms preprocess, 24.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 26.4ms\n",
      "Speed: 1.9ms preprocess, 26.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 26.0ms\n",
      "Speed: 1.7ms preprocess, 26.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.6ms\n",
      "Speed: 2.2ms preprocess, 25.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 26.5ms\n",
      "Speed: 2.2ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 26.2ms\n",
      "Speed: 2.0ms preprocess, 26.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 25.8ms\n",
      "Speed: 2.3ms preprocess, 25.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 25.4ms\n",
      "Speed: 1.9ms preprocess, 25.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 26.2ms\n",
      "Speed: 1.9ms preprocess, 26.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 25.8ms\n",
      "Speed: 3.8ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 26.3ms\n",
      "Speed: 2.0ms preprocess, 26.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 25.7ms\n",
      "Speed: 2.0ms preprocess, 25.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 25.7ms\n",
      "Speed: 2.1ms preprocess, 25.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 25.8ms\n",
      "Speed: 2.3ms preprocess, 25.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 26.0ms\n",
      "Speed: 2.2ms preprocess, 26.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 25.4ms\n",
      "Speed: 2.2ms preprocess, 25.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 26.0ms\n",
      "Speed: 2.2ms preprocess, 26.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 26.0ms\n",
      "Speed: 2.2ms preprocess, 26.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 25.0ms\n",
      "Speed: 1.8ms preprocess, 25.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 25.2ms\n",
      "Speed: 2.4ms preprocess, 25.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 25.2ms\n",
      "Speed: 1.9ms preprocess, 25.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 24.9ms\n",
      "Speed: 3.0ms preprocess, 24.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 25.1ms\n",
      "Speed: 2.0ms preprocess, 25.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.3ms\n",
      "Speed: 2.2ms preprocess, 25.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 24.7ms\n",
      "Speed: 2.9ms preprocess, 24.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.2ms\n",
      "Speed: 1.9ms preprocess, 25.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 24.8ms\n",
      "Speed: 1.8ms preprocess, 24.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 24.6ms\n",
      "Speed: 1.8ms preprocess, 24.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 24.6ms\n",
      "Speed: 2.3ms preprocess, 24.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.2ms\n",
      "Speed: 1.8ms preprocess, 25.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.0ms\n",
      "Speed: 2.2ms preprocess, 25.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.5ms\n",
      "Speed: 2.6ms preprocess, 25.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 24.7ms\n",
      "Speed: 2.2ms preprocess, 24.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 24.6ms\n",
      "Speed: 2.1ms preprocess, 24.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 26.2ms\n",
      "Speed: 1.8ms preprocess, 26.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 26.3ms\n",
      "Speed: 1.8ms preprocess, 26.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.8ms\n",
      "Speed: 2.1ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.7ms\n",
      "Speed: 2.3ms preprocess, 25.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Отвлечение на кадре_01:53\n",
      "Отвлечение на кадре_01:54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 2 persons, 26.2ms\n",
      "Speed: 2.2ms preprocess, 26.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.9ms\n",
      "Speed: 2.2ms preprocess, 25.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.8ms\n",
      "Speed: 1.9ms preprocess, 25.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.4ms\n",
      "Speed: 2.9ms preprocess, 25.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 26.7ms\n",
      "Speed: 1.9ms preprocess, 26.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.9ms\n",
      "Speed: 2.0ms preprocess, 25.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.4ms\n",
      "Speed: 1.7ms preprocess, 25.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.7ms\n",
      "Speed: 2.4ms preprocess, 25.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 26.3ms\n",
      "Speed: 2.4ms preprocess, 26.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 26.2ms\n",
      "Speed: 2.4ms preprocess, 26.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 26.3ms\n",
      "Speed: 2.0ms preprocess, 26.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.6ms\n",
      "Speed: 2.2ms preprocess, 25.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.1ms\n",
      "Speed: 2.1ms preprocess, 25.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.8ms\n",
      "Speed: 2.1ms preprocess, 25.8ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.5ms\n",
      "Speed: 2.1ms preprocess, 25.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.3ms\n",
      "Speed: 3.1ms preprocess, 25.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 24.6ms\n",
      "Speed: 2.0ms preprocess, 24.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 26.5ms\n",
      "Speed: 5.5ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.4ms\n",
      "Speed: 2.3ms preprocess, 25.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 24.8ms\n",
      "Speed: 2.1ms preprocess, 24.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 24.7ms\n",
      "Speed: 2.5ms preprocess, 24.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 24.8ms\n",
      "Speed: 2.5ms preprocess, 24.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 24.9ms\n",
      "Speed: 3.5ms preprocess, 24.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.3ms\n",
      "Speed: 2.2ms preprocess, 25.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.2ms\n",
      "Speed: 2.6ms preprocess, 25.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 24.6ms\n",
      "Speed: 3.3ms preprocess, 24.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 26.1ms\n",
      "Speed: 2.2ms preprocess, 26.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.5ms\n",
      "Speed: 3.7ms preprocess, 25.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 26.3ms\n",
      "Speed: 1.9ms preprocess, 26.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 26.0ms\n",
      "Speed: 2.2ms preprocess, 26.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 26.0ms\n",
      "Speed: 2.2ms preprocess, 26.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 26.1ms\n",
      "Speed: 2.2ms preprocess, 26.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.5ms\n",
      "Speed: 2.3ms preprocess, 25.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.7ms\n",
      "Speed: 1.9ms preprocess, 25.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.8ms\n",
      "Speed: 2.1ms preprocess, 25.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 26.0ms\n",
      "Speed: 2.4ms preprocess, 26.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.8ms\n",
      "Speed: 2.0ms preprocess, 25.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 26.5ms\n",
      "Speed: 1.8ms preprocess, 26.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 27.1ms\n",
      "Speed: 2.0ms preprocess, 27.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.4ms\n",
      "Speed: 2.3ms preprocess, 25.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 26.1ms\n",
      "Speed: 2.3ms preprocess, 26.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 26.6ms\n",
      "Speed: 2.1ms preprocess, 26.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.7ms\n",
      "Speed: 2.1ms preprocess, 25.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 24.9ms\n",
      "Speed: 2.2ms preprocess, 24.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.4ms\n",
      "Speed: 1.7ms preprocess, 25.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 24.9ms\n",
      "Speed: 2.2ms preprocess, 24.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 24.3ms\n",
      "Speed: 2.3ms preprocess, 24.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 24.6ms\n",
      "Speed: 1.8ms preprocess, 24.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.3ms\n",
      "Speed: 1.9ms preprocess, 25.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 24.7ms\n",
      "Speed: 1.9ms preprocess, 24.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 24.5ms\n",
      "Speed: 2.2ms preprocess, 24.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.0ms\n",
      "Speed: 1.7ms preprocess, 25.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.4ms\n",
      "Speed: 1.8ms preprocess, 25.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.9ms\n",
      "Speed: 2.1ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 24.9ms\n",
      "Speed: 2.0ms preprocess, 24.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.4ms\n",
      "Speed: 2.1ms preprocess, 25.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 24.4ms\n",
      "Speed: 2.0ms preprocess, 24.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.4ms\n",
      "Speed: 1.8ms preprocess, 25.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 24.8ms\n",
      "Speed: 2.0ms preprocess, 24.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 26.1ms\n",
      "Speed: 1.7ms preprocess, 26.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 26.2ms\n",
      "Speed: 1.8ms preprocess, 26.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.6ms\n",
      "Speed: 2.0ms preprocess, 25.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 26.3ms\n",
      "Speed: 2.0ms preprocess, 26.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.7ms\n",
      "Speed: 2.2ms preprocess, 25.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.9ms\n",
      "Speed: 2.1ms preprocess, 25.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 26.1ms\n",
      "Speed: 1.8ms preprocess, 26.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.7ms\n",
      "Speed: 2.1ms preprocess, 25.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.5ms\n",
      "Speed: 2.4ms preprocess, 25.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 27.3ms\n",
      "Speed: 2.1ms preprocess, 27.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 26.1ms\n",
      "Speed: 2.1ms preprocess, 26.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 25.8ms\n",
      "Speed: 2.1ms preprocess, 25.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 26.3ms\n",
      "Speed: 2.4ms preprocess, 26.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 26.5ms\n",
      "Speed: 2.5ms preprocess, 26.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 26.1ms\n",
      "Speed: 1.8ms preprocess, 26.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.7ms\n",
      "Speed: 1.7ms preprocess, 25.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Отвлечение на кадре_03:07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 2 persons, 24.7ms\n",
      "Speed: 2.2ms preprocess, 24.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.2ms\n",
      "Speed: 1.7ms preprocess, 25.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.3ms\n",
      "Speed: 1.9ms preprocess, 25.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 24.6ms\n",
      "Speed: 2.1ms preprocess, 24.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.3ms\n",
      "Speed: 2.2ms preprocess, 25.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 24.9ms\n",
      "Speed: 1.7ms preprocess, 24.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 24.6ms\n",
      "Speed: 2.2ms preprocess, 24.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.0ms\n",
      "Speed: 2.1ms preprocess, 25.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 24.6ms\n",
      "Speed: 2.1ms preprocess, 24.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 24.6ms\n",
      "Speed: 1.8ms preprocess, 24.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 24.6ms\n",
      "Speed: 1.9ms preprocess, 24.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 24.6ms\n",
      "Speed: 2.2ms preprocess, 24.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.4ms\n",
      "Speed: 2.1ms preprocess, 25.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 24.8ms\n",
      "Speed: 3.3ms preprocess, 24.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 24.5ms\n",
      "Speed: 1.8ms preprocess, 24.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.0ms\n",
      "Speed: 2.2ms preprocess, 25.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.2ms\n",
      "Speed: 2.2ms preprocess, 25.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.9ms\n",
      "Speed: 1.9ms preprocess, 25.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 25.8ms\n",
      "Speed: 2.3ms preprocess, 25.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.6ms\n",
      "Speed: 1.9ms preprocess, 25.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 26.5ms\n",
      "Speed: 2.1ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.9ms\n",
      "Speed: 2.0ms preprocess, 25.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.7ms\n",
      "Speed: 1.8ms preprocess, 25.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.3ms\n",
      "Speed: 2.7ms preprocess, 25.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 26.7ms\n",
      "Speed: 1.9ms preprocess, 26.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 26.3ms\n",
      "Speed: 2.2ms preprocess, 26.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 26.0ms\n",
      "Speed: 1.8ms preprocess, 26.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.2ms\n",
      "Speed: 2.4ms preprocess, 25.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.3ms\n",
      "Speed: 2.4ms preprocess, 25.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 26.2ms\n",
      "Speed: 1.9ms preprocess, 26.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.6ms\n",
      "Speed: 1.9ms preprocess, 25.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.1ms\n",
      "Speed: 2.1ms preprocess, 25.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.8ms\n",
      "Speed: 2.1ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.6ms\n",
      "Speed: 2.7ms preprocess, 25.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 24.3ms\n",
      "Speed: 1.9ms preprocess, 24.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.6ms\n",
      "Speed: 2.1ms preprocess, 25.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.8ms\n",
      "Speed: 2.2ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 24.6ms\n",
      "Speed: 2.0ms preprocess, 24.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 24.7ms\n",
      "Speed: 2.6ms preprocess, 24.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 24.1ms\n",
      "Speed: 3.0ms preprocess, 24.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 24.1ms\n",
      "Speed: 2.2ms preprocess, 24.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.1ms\n",
      "Speed: 2.4ms preprocess, 25.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 24.4ms\n",
      "Speed: 2.1ms preprocess, 24.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 24.2ms\n",
      "Speed: 2.0ms preprocess, 24.2ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 24.3ms\n",
      "Speed: 2.1ms preprocess, 24.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.4ms\n",
      "Speed: 2.6ms preprocess, 25.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 24.6ms\n",
      "Speed: 2.1ms preprocess, 24.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 24.2ms\n",
      "Speed: 1.9ms preprocess, 24.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 26.4ms\n",
      "Speed: 2.5ms preprocess, 26.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.5ms\n",
      "Speed: 2.1ms preprocess, 25.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.5ms\n",
      "Speed: 3.1ms preprocess, 25.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.5ms\n",
      "Speed: 1.8ms preprocess, 25.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 26.2ms\n",
      "Speed: 2.3ms preprocess, 26.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 26.0ms\n",
      "Speed: 2.8ms preprocess, 26.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.4ms\n",
      "Speed: 1.7ms preprocess, 25.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 26.7ms\n",
      "Speed: 1.8ms preprocess, 26.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.3ms\n",
      "Speed: 2.0ms preprocess, 25.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.3ms\n",
      "Speed: 2.2ms preprocess, 25.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 26.4ms\n",
      "Speed: 2.8ms preprocess, 26.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 26.4ms\n",
      "Speed: 2.2ms preprocess, 26.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.7ms\n",
      "Speed: 2.1ms preprocess, 25.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.4ms\n",
      "Speed: 2.1ms preprocess, 25.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.9ms\n",
      "Speed: 2.6ms preprocess, 25.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.4ms\n",
      "Speed: 1.9ms preprocess, 25.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 24.4ms\n",
      "Speed: 2.6ms preprocess, 24.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Отвлечение на кадре_04:12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 2 persons, 25.2ms\n",
      "Speed: 1.8ms preprocess, 25.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 24.6ms\n",
      "Speed: 2.1ms preprocess, 24.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 26.1ms\n",
      "Speed: 1.9ms preprocess, 26.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 24.5ms\n",
      "Speed: 1.9ms preprocess, 24.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 24.1ms\n",
      "Speed: 1.9ms preprocess, 24.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.9ms\n",
      "Speed: 2.9ms preprocess, 25.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 24.1ms\n",
      "Speed: 2.5ms preprocess, 24.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Отвлечение на кадре_04:19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 2 persons, 24.4ms\n",
      "Speed: 1.8ms preprocess, 24.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 24.9ms\n",
      "Speed: 2.1ms preprocess, 24.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 24.5ms\n",
      "Speed: 1.9ms preprocess, 24.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 24.3ms\n",
      "Speed: 1.9ms preprocess, 24.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.3ms\n",
      "Speed: 2.3ms preprocess, 25.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.5ms\n",
      "Speed: 2.6ms preprocess, 25.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 24.6ms\n",
      "Speed: 2.0ms preprocess, 24.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 26.2ms\n",
      "Speed: 2.1ms preprocess, 26.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.6ms\n",
      "Speed: 2.5ms preprocess, 25.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Отвлечение на кадре_04:28\n",
      "Отвлечение на кадре_04:30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 persons, 25.8ms\n",
      "Speed: 2.1ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 26.7ms\n",
      "Speed: 2.0ms preprocess, 26.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 26.2ms\n",
      "Speed: 2.2ms preprocess, 26.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Отвлечение на кадре_04:31\n",
      "Отвлечение на кадре_04:33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 persons, 26.5ms\n",
      "Speed: 2.5ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.7ms\n",
      "Speed: 2.1ms preprocess, 25.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Отвлечение на кадре_04:34\n",
      "Отвлечение на кадре_04:35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 2 persons, 27.2ms\n",
      "Speed: 2.8ms preprocess, 27.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.4ms\n",
      "Speed: 2.3ms preprocess, 25.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Отвлечение на кадре_04:36\n",
      "Отвлечение на кадре_04:37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 2 persons, 26.6ms\n",
      "Speed: 2.1ms preprocess, 26.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 24.1ms\n",
      "Speed: 2.4ms preprocess, 24.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Отвлечение на кадре_04:38\n",
      "Отвлечение на кадре_04:39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 2 persons, 24.9ms\n",
      "Speed: 2.3ms preprocess, 24.9ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.5ms\n",
      "Speed: 2.1ms preprocess, 25.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.4ms\n",
      "Speed: 2.1ms preprocess, 25.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Отвлечение на кадре_04:40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 2 persons, 24.7ms\n",
      "Speed: 2.0ms preprocess, 24.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 24.3ms\n",
      "Speed: 2.4ms preprocess, 24.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 24.7ms\n",
      "Speed: 2.2ms preprocess, 24.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 24.2ms\n",
      "Speed: 2.0ms preprocess, 24.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Отвлечение на кадре_04:44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 2 persons, 25.0ms\n",
      "Speed: 2.1ms preprocess, 25.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 24.1ms\n",
      "Speed: 1.8ms preprocess, 24.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 26.9ms\n",
      "Speed: 1.7ms preprocess, 26.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.7ms\n",
      "Speed: 2.4ms preprocess, 25.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 24.6ms\n",
      "Speed: 2.4ms preprocess, 24.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 24.9ms\n",
      "Speed: 2.5ms preprocess, 24.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 27.2ms\n",
      "Speed: 2.1ms preprocess, 27.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 26.4ms\n",
      "Speed: 2.2ms preprocess, 26.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Отвлечение на кадре_04:53\n",
      "Отвлечение на кадре_04:54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 2 persons, 26.5ms\n",
      "Speed: 1.9ms preprocess, 26.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.5ms\n",
      "Speed: 2.4ms preprocess, 25.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.6ms\n",
      "Speed: 2.1ms preprocess, 25.6ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 27.6ms\n",
      "Speed: 2.5ms preprocess, 27.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Отвлечение на кадре_04:57\n",
      "Отвлечение на кадре_04:58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 2 persons, 26.3ms\n",
      "Speed: 1.8ms preprocess, 26.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.6ms\n",
      "Speed: 3.3ms preprocess, 25.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 27.0ms\n",
      "Speed: 2.4ms preprocess, 27.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 26.5ms\n",
      "Speed: 2.1ms preprocess, 26.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.3ms\n",
      "Speed: 2.5ms preprocess, 25.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.6ms\n",
      "Speed: 2.3ms preprocess, 25.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.4ms\n",
      "Speed: 2.2ms preprocess, 25.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Отвлечение на кадре_05:03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 2 persons, 25.0ms\n",
      "Speed: 2.0ms preprocess, 25.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.5ms\n",
      "Speed: 2.2ms preprocess, 25.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 24.9ms\n",
      "Speed: 1.9ms preprocess, 24.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Отвлечение на кадре_05:06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 2 persons, 24.4ms\n",
      "Speed: 2.0ms preprocess, 24.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 25.5ms\n",
      "Speed: 2.0ms preprocess, 25.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 24.1ms\n",
      "Speed: 1.9ms preprocess, 24.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.2ms\n",
      "Speed: 2.5ms preprocess, 25.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.6ms\n",
      "Speed: 1.7ms preprocess, 25.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.5ms\n",
      "Speed: 2.1ms preprocess, 25.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 24.5ms\n",
      "Speed: 2.4ms preprocess, 24.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Отвлечение на кадре_05:13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 2 persons, 24.3ms\n",
      "Speed: 2.3ms preprocess, 24.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 24.5ms\n",
      "Speed: 2.1ms preprocess, 24.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 24.2ms\n",
      "Speed: 2.2ms preprocess, 24.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 24.9ms\n",
      "Speed: 2.2ms preprocess, 24.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 24.7ms\n",
      "Speed: 1.9ms preprocess, 24.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.6ms\n",
      "Speed: 2.3ms preprocess, 25.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 26.2ms\n",
      "Speed: 1.9ms preprocess, 26.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.6ms\n",
      "Speed: 2.0ms preprocess, 25.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.7ms\n",
      "Speed: 2.5ms preprocess, 25.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 26.8ms\n",
      "Speed: 2.0ms preprocess, 26.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.7ms\n",
      "Speed: 1.9ms preprocess, 25.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.5ms\n",
      "Speed: 2.1ms preprocess, 25.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 26.7ms\n",
      "Speed: 3.7ms preprocess, 26.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 26.6ms\n",
      "Speed: 2.1ms preprocess, 26.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 26.0ms\n",
      "Speed: 2.2ms preprocess, 26.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.5ms\n",
      "Speed: 2.5ms preprocess, 25.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 26.9ms\n",
      "Speed: 2.1ms preprocess, 26.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 26.2ms\n",
      "Speed: 2.1ms preprocess, 26.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.5ms\n",
      "Speed: 2.2ms preprocess, 25.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.9ms\n",
      "Speed: 2.4ms preprocess, 25.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.2ms\n",
      "Speed: 2.1ms preprocess, 25.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.0ms\n",
      "Speed: 3.5ms preprocess, 25.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.1ms\n",
      "Speed: 2.3ms preprocess, 25.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 26.7ms\n",
      "Speed: 2.9ms preprocess, 26.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.0ms\n",
      "Speed: 2.0ms preprocess, 25.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 24.6ms\n",
      "Speed: 2.2ms preprocess, 24.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 24.6ms\n",
      "Speed: 1.8ms preprocess, 24.6ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.1ms\n",
      "Speed: 2.2ms preprocess, 25.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.7ms\n",
      "Speed: 2.2ms preprocess, 25.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 24.4ms\n",
      "Speed: 2.0ms preprocess, 24.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.3ms\n",
      "Speed: 2.4ms preprocess, 25.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 24.8ms\n",
      "Speed: 1.8ms preprocess, 24.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 24.8ms\n",
      "Speed: 2.2ms preprocess, 24.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 24.7ms\n",
      "Speed: 1.9ms preprocess, 24.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.6ms\n",
      "Speed: 2.7ms preprocess, 25.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 24.7ms\n",
      "Speed: 2.0ms preprocess, 24.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.1ms\n",
      "Speed: 2.1ms preprocess, 25.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 26.4ms\n",
      "Speed: 1.9ms preprocess, 26.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.6ms\n",
      "Speed: 2.0ms preprocess, 25.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.9ms\n",
      "Speed: 2.2ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 26.4ms\n",
      "Speed: 2.4ms preprocess, 26.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 27.0ms\n",
      "Speed: 2.2ms preprocess, 27.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.9ms\n",
      "Speed: 2.3ms preprocess, 25.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.6ms\n",
      "Speed: 2.6ms preprocess, 25.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.9ms\n",
      "Speed: 2.4ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.9ms\n",
      "Speed: 1.9ms preprocess, 25.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.5ms\n",
      "Speed: 2.1ms preprocess, 25.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 26.3ms\n",
      "Speed: 2.0ms preprocess, 26.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 26.0ms\n",
      "Speed: 2.0ms preprocess, 26.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.7ms\n",
      "Speed: 2.1ms preprocess, 25.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.5ms\n",
      "Speed: 2.5ms preprocess, 25.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.4ms\n",
      "Speed: 2.3ms preprocess, 25.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 26.0ms\n",
      "Speed: 2.3ms preprocess, 26.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 24.2ms\n",
      "Speed: 2.4ms preprocess, 24.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.5ms\n",
      "Speed: 1.8ms preprocess, 25.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 24.4ms\n",
      "Speed: 2.2ms preprocess, 24.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.8ms\n",
      "Speed: 2.0ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 24.1ms\n",
      "Speed: 2.1ms preprocess, 24.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 25.7ms\n",
      "Speed: 1.8ms preprocess, 25.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 24.8ms\n",
      "Speed: 2.1ms preprocess, 24.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.0ms\n",
      "Speed: 2.0ms preprocess, 25.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 24.9ms\n",
      "Speed: 2.1ms preprocess, 24.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 24.7ms\n",
      "Speed: 1.9ms preprocess, 24.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 24.8ms\n",
      "Speed: 2.4ms preprocess, 24.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 24.4ms\n",
      "Speed: 1.9ms preprocess, 24.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.6ms\n",
      "Speed: 2.1ms preprocess, 25.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 24.7ms\n",
      "Speed: 2.1ms preprocess, 24.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 24.9ms\n",
      "Speed: 2.2ms preprocess, 24.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 24.8ms\n",
      "Speed: 1.9ms preprocess, 24.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.1ms\n",
      "Speed: 2.0ms preprocess, 25.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.4ms\n",
      "Speed: 2.2ms preprocess, 25.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 26.3ms\n",
      "Speed: 2.1ms preprocess, 26.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.7ms\n",
      "Speed: 2.2ms preprocess, 25.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 26.0ms\n",
      "Speed: 1.9ms preprocess, 26.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.6ms\n",
      "Speed: 2.6ms preprocess, 25.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.8ms\n",
      "Speed: 2.3ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 26.5ms\n",
      "Speed: 2.3ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.3ms\n",
      "Speed: 1.9ms preprocess, 25.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 26.0ms\n",
      "Speed: 2.2ms preprocess, 26.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 26.2ms\n",
      "Speed: 1.7ms preprocess, 26.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.4ms\n",
      "Speed: 2.0ms preprocess, 25.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 26.1ms\n",
      "Speed: 2.5ms preprocess, 26.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.6ms\n",
      "Speed: 1.9ms preprocess, 25.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.9ms\n",
      "Speed: 1.9ms preprocess, 25.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 26.1ms\n",
      "Speed: 2.1ms preprocess, 26.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 26.4ms\n",
      "Speed: 1.7ms preprocess, 26.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 24.7ms\n",
      "Speed: 1.8ms preprocess, 24.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.5ms\n",
      "Speed: 2.1ms preprocess, 25.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 24.8ms\n",
      "Speed: 2.2ms preprocess, 24.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 24.6ms\n",
      "Speed: 1.8ms preprocess, 24.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 24.7ms\n",
      "Speed: 2.2ms preprocess, 24.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 24.7ms\n",
      "Speed: 1.9ms preprocess, 24.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 24.8ms\n",
      "Speed: 2.3ms preprocess, 24.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 24.3ms\n",
      "Speed: 2.1ms preprocess, 24.3ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.6ms\n",
      "Speed: 2.0ms preprocess, 25.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 24.7ms\n",
      "Speed: 1.7ms preprocess, 24.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.1ms\n",
      "Speed: 2.2ms preprocess, 25.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 24.6ms\n",
      "Speed: 1.8ms preprocess, 24.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.7ms\n",
      "Speed: 1.8ms preprocess, 25.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 24.8ms\n",
      "Speed: 2.8ms preprocess, 24.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 24.2ms\n",
      "Speed: 3.0ms preprocess, 24.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 26.4ms\n",
      "Speed: 1.8ms preprocess, 26.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 25.1ms\n",
      "Speed: 2.1ms preprocess, 25.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.5ms\n",
      "Speed: 2.1ms preprocess, 25.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.3ms\n",
      "Speed: 2.7ms preprocess, 25.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 26.5ms\n",
      "Speed: 1.8ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.7ms\n",
      "Speed: 2.0ms preprocess, 25.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.7ms\n",
      "Speed: 2.4ms preprocess, 25.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 26.1ms\n",
      "Speed: 2.2ms preprocess, 26.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 26.4ms\n",
      "Speed: 2.2ms preprocess, 26.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.1ms\n",
      "Speed: 2.1ms preprocess, 25.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.8ms\n",
      "Speed: 2.0ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 26.2ms\n",
      "Speed: 2.2ms preprocess, 26.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.6ms\n",
      "Speed: 2.2ms preprocess, 25.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.7ms\n",
      "Speed: 2.0ms preprocess, 25.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 26.1ms\n",
      "Speed: 2.0ms preprocess, 26.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.8ms\n",
      "Speed: 2.0ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.7ms\n",
      "Speed: 1.9ms preprocess, 25.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from copy import deepcopy\n",
    "import csv\n",
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "\n",
    "\n",
    "# Параметры\n",
    "THRESHOLD = 100  # Евклидово расстояние для определения близости\n",
    "UD_THRESHOLD = 30  # Порог вертикального отклонения\n",
    "\n",
    "# Инициализация моделей\n",
    "yolo_pose = YOLO('yolov8s-pose.pt')\n",
    "\n",
    "# Координаты прямоугольника\n",
    "RECT_X1, RECT_Y1 = 930, 485\n",
    "RECT_X2, RECT_Y2 = 1425, 295\n",
    "\n",
    "global total_time_with_person\n",
    "total_time_with_person = 0\n",
    "global time_without_hands\n",
    "time_without_hands = 0\n",
    "global time_without_person\n",
    "time_without_person = 0\n",
    "\n",
    "def wrist_in_rectangle(wrist):\n",
    "    \"\"\"\n",
    "    Checks if the wrist point is inside the defined rectangle.\n",
    "    \n",
    "    :param wrist: Coordinates of the wrist.\n",
    "    :return: True if inside, False otherwise.\n",
    "    \"\"\"\n",
    "    x, y = wrist\n",
    "    return RECT_X1 <= x <= RECT_X2 and RECT_Y2 <= y <= RECT_Y1\n",
    "\n",
    "\n",
    "def detect_frame_difference(current_frame, prev_frame, mask=None, diff_threshold=30, pixel_threshold=500):\n",
    "    \"\"\"\n",
    "    Detects significant changes between two frames.\n",
    "\n",
    "    :param current_frame: Current frame.\n",
    "    :param prev_frame: Previous frame.\n",
    "    :param mask: Optional mask to specify region of interest.\n",
    "    :param diff_threshold: Threshold for pixel difference.\n",
    "    :param pixel_threshold: Threshold for number of changed pixels.\n",
    "    :return: True if significant change detected, False otherwise.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Конвертируем кадры в оттенки серого\n",
    "    current_gray = cv2.cvtColor(current_frame, cv2.COLOR_BGR2GRAY)\n",
    "    prev_gray = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Применяем маску, если она предоставлена\n",
    "    if mask is not None:\n",
    "        current_gray = cv2.bitwise_and(current_gray, current_gray, mask=mask)\n",
    "        prev_gray = cv2.bitwise_and(prev_gray, prev_gray, mask=mask)\n",
    "    \n",
    "    # Вычисляем абсолютное различие между кадрами\n",
    "    diff = cv2.absdiff(current_gray, prev_gray)\n",
    "    \n",
    "    # Применяем порог\n",
    "    _, thresh_diff = cv2.threshold(diff, diff_threshold, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    # Считаем ненулевые пиксели\n",
    "    changed_pixels = cv2.countNonZero(thresh_diff)\n",
    "    \n",
    "    return changed_pixels > pixel_threshold\n",
    "\n",
    "\n",
    "def get_intervals(distractions, gap=60):\n",
    "    \"\"\"\n",
    "    Retrieves intervals of distractions.\n",
    "\n",
    "    :param distractions: List of detected distraction times.\n",
    "    :param gap: Gap time to consider for intervals.\n",
    "    :return: List of intervals.\n",
    "    \"\"\"\n",
    "    if not distractions:\n",
    "        return []\n",
    "    \n",
    "    intervals = [[distractions[0], distractions[0]]]\n",
    "    for t in distractions[1:]:\n",
    "        if t - intervals[-1][1] <= gap:\n",
    "            intervals[-1][1] = t\n",
    "        else:\n",
    "            intervals.append([t, t])\n",
    "    return intervals\n",
    "\n",
    "\n",
    "def seconds_to_time(seconds):\n",
    "    \"\"\"\n",
    "    Converts seconds to time format MM:SS.\n",
    "\n",
    "    :param seconds: Time in seconds.\n",
    "    :return: Time in MM:SS format.\n",
    "    \"\"\"\n",
    "    minutes, seconds = divmod(seconds, 60)\n",
    "    minutes, seconds = int(minutes), int(seconds)\n",
    "    if minutes < 10:\n",
    "        minutes = f\"0{minutes}\"\n",
    "    if seconds < 10:\n",
    "        seconds = f\"0{seconds}\"\n",
    "    return f\"{minutes}:{seconds}\"\n",
    "\n",
    "\n",
    "def process_all_videos_in_folder(folder_path, SAVE_PATH):\n",
    "    \"\"\"\n",
    "    Processes all videos in the specified folder.\n",
    "\n",
    "    :param folder_path: Path to the video folder.\n",
    "    :param SAVE_PATH: Path to save processed outputs.\n",
    "    \"\"\"\n",
    "    # Получаем все файлы в папке\n",
    "    all_files = os.listdir(folder_path)\n",
    "    \n",
    "    # Фильтруем только .mp4 файлы\n",
    "    mp4_files = [file for file in all_files if file.endswith('.mp4')]\n",
    "    \n",
    "    # Обрабатываем каждый файл\n",
    "    for mp4_file in mp4_files:\n",
    "        video_path = os.path.join(folder_path, mp4_file)\n",
    "        video_name = os.path.splitext(mp4_file)[0]  # Убираем расширение\n",
    "        process_video(video_path, SAVE_PATH, video_name)\n",
    "\n",
    "\n",
    "def process_video(video_path, SAVE_PATH, video_name):\n",
    "    \"\"\"\n",
    "    Processes a single video.\n",
    "\n",
    "    :param video_path: Path to the video.\n",
    "    :param SAVE_PATH: Path to save processed outputs.\n",
    "    :param video_name: Name of the video.\n",
    "    \"\"\"\n",
    "\n",
    "    global total_time_with_person\n",
    "    global time_without_hands\n",
    "    global time_without_person\n",
    "\n",
    "    distractions = []\n",
    "    # Создаем папку с именем видео, если она не существует\n",
    "    video_folder_path = os.path.join(SAVE_PATH, video_name)\n",
    "    if not os.path.exists(video_folder_path):\n",
    "        os.mkdir(video_folder_path)\n",
    "    \n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    frame_count = 0\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        frame_count += 1\n",
    "        \n",
    "        if frame_count % fps != 0:\n",
    "            continue\n",
    "\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        # Прогноз с помощью модели позы\n",
    "        results_pose = yolo_pose.predict(frame)\n",
    "        \n",
    "        # Получаем ключевые точки для всех обнаруженных объектов\n",
    "        keypoints = results_pose[0].keypoints.xy\n",
    "        \n",
    "        distraction_detected = False\n",
    "\n",
    "        all_wrists = []\n",
    "\n",
    "        for person_keypoints in keypoints:\n",
    "            wrists = []  # Список для сохранения координат обеих запястий\n",
    "            colors = [(128, 0, 128), (0, 255, 255)]  # Фиолетовый и желтый цвета для визуализации\n",
    "\n",
    "            # Извлекаем ключевые точки запястий\n",
    "            for idx in [9, 10]:  # Индексы для левого и правого запястья\n",
    "                try:\n",
    "                    wrist = person_keypoints[idx].cpu().numpy()\n",
    "                    all_wrists.append(wrist)\n",
    "                    wrists.append(wrist)\n",
    "                except:\n",
    "                    wrists.append(wrist)\n",
    "                    continue\n",
    "            \n",
    "            # Считаем количество видимых ключевых точек\n",
    "            visible_keypoints = sum(1 for keypoint in person_keypoints if keypoint is not None)\n",
    "\n",
    "            # Проверяем, есть ли по крайней мере 15 видимых ключевых точек\n",
    "            if visible_keypoints < 14:\n",
    "                continue\n",
    "\n",
    "            bottom_height_limit = 0.85 * frame.shape[0]  # 85% от высоты изображения\n",
    "            upper_height_limit = 0.35 * frame.shape[0]  # 35% от высоты изображения\n",
    "\n",
    "            # Проверяем расстояние между двумя запястьями\n",
    "            if wrists[0] is not None and wrists[1] is not None:\n",
    "                distance = np.linalg.norm(np.array(wrists[0]) - np.array(wrists[1]))\n",
    "                # Проверяем условия для определения отвлечения\n",
    "                if distance < THRESHOLD and wrists[0][0] < wrists[1][0] and abs(wrists[0][1] - wrists[1][1]) <= UD_THRESHOLD and wrists[0][1] < bottom_height_limit and wrists[1][1] < bottom_height_limit and wrists[0][1] > upper_height_limit and wrists[1][1] > upper_height_limit:\n",
    "                    distraction_detected = True\n",
    "                    for wrist, color in zip(wrists, colors):\n",
    "                        cv2.circle(frame, (int(wrist[0]), int(wrist[1])), 10, color, -1)\n",
    "                    break\n",
    "\n",
    "        # После цикла проверяем, находится ли хотя бы одно запястье в прямоугольнике\n",
    "        hands_in_rect = any([wrist_in_rectangle(wrist) for wrist in all_wrists])\n",
    "\n",
    "        person_on_right = any([kp[0] > frame.shape[1] / 2 for person_kps in keypoints for kp in person_kps if kp is not None])\n",
    "\n",
    "        if person_on_right:\n",
    "            total_time_with_person += 1\n",
    "            if not hands_in_rect:\n",
    "                time_without_hands += 1\n",
    "        else:\n",
    "            time_without_person += 1\n",
    "\n",
    "        if distraction_detected:\n",
    "            frame_count_copy = deepcopy(frame_count)\n",
    "            distractions.append(frame_count_copy/12)\n",
    "            print(f\"Отвлечение на кадре_{seconds_to_time(frame_count_copy/12)}\")\n",
    "            save_path = os.path.join(video_folder_path, f\"{seconds_to_time(frame_count_copy/12)}.jpg\")\n",
    "            cv2.imwrite(save_path, frame)\n",
    "\n",
    "    intervals = get_intervals(distractions)\n",
    "    with open(os.path.join(SAVE_PATH, f\"{video_name}_intervals.csv\"), \"w\", newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow([\"Start Time\", \"End Time\"])\n",
    "        for interval in intervals:\n",
    "            writer.writerow([seconds_to_time(interval[0]), seconds_to_time(interval[1])])\n",
    "        \n",
    "        # Добавляем статистику по времени\n",
    "        percentage_without_hands = (time_without_hands / total_time_with_person) * 100 if total_time_with_person != 0 else 0\n",
    "        writer.writerow([])\n",
    "        writer.writerow([\"Total Time With Person (frames)\", total_time_with_person])\n",
    "        writer.writerow([\"Time Without Hands (frames)\", time_without_hands])\n",
    "        writer.writerow([\"Time Without Person (frames)\", time_without_person])\n",
    "        writer.writerow([\"Percentage Without Hands (%)\", percentage_without_hands])\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "folder_path = \"/home/student/snap/code/Hackathons/Haborovsk/Анализ бригад (телефон)/Есть телефон\"\n",
    "SAVE_PATH = \"/home/student/snap/code/Hackathons/Haborovsk/Анализ бригад (телефон)/img_with_phones\"\n",
    "SAVE_PATH2 = \"/home/student/snap/code/Hackathons/Haborovsk/Анализ бригад (телефон)/img_without_phones\"\n",
    "if not os.path.exists(SAVE_PATH):\n",
    "    os.mkdir(SAVE_PATH)\n",
    "\n",
    "#process_all_videos_in_folder(folder_path, SAVE_PATH)\n",
    "video_name = \"00_26_30\"\n",
    "process_video(f\"/home/student/snap/code/Hackathons/Haborovsk/Анализ бригад (телефон)/Есть телефон/{video_name}.mp4\", SAVE_PATH, video_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOLO-NAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install numpy \n",
    "# %pip install ultralytics \n",
    "# %pip install tensorflow tf-models-official tensorflow_hub \n",
    "# %pip install opencv-python \n",
    "# %pip install matplotlib \n",
    "# %pip install Pillow \n",
    "# %pip install super_gradients \n",
    "# %pip install torch torchvision pytorch-quantization  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "import super_gradients\n",
    "import os\n",
    "\n",
    "coco_interesting_classes=[0,16,17,18,27,31,33,39,44,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,73,77,84]\n",
    "\n",
    "# 1. Инициализация моделей\n",
    "device = torch.device(\"cuda:0\")  # для использования первой GPU\n",
    "\n",
    "# 1. Инициализация моделей\n",
    "yolo_nas = super_gradients.training.models.get(\"yolo_nas_s\", pretrained_weights=\"coco\").to(device)\n",
    "yolo_pose = YOLO('yolov8s-pose.pt')\n",
    "\n",
    "# Параметры\n",
    "THRESHOLD = 25  # Евклидово расстояние для определения близости\n",
    "frames_with_phone = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seconds_to_time(seconds):\n",
    "    minutes, seconds = divmod(seconds, 60)\n",
    "    minutes, seconds = int(minutes), int(seconds)\n",
    "    if minutes < 10:\n",
    "        minutes = f\"0{minutes}\"\n",
    "    if seconds < 10:\n",
    "        seconds = f\"0{seconds}\"\n",
    "    return f\"{minutes}:{seconds}\"\n",
    "\n",
    "\n",
    "def process_all_videos_in_folder(folder_path, SAVE_PATH):\n",
    "    # Получаем список всех файлов в папке\n",
    "    all_files = os.listdir(folder_path)\n",
    "    \n",
    "    # Отбираем только файлы с расширением .mp4\n",
    "    mp4_files = [file for file in all_files if file.endswith('.mp4')]\n",
    "    \n",
    "    # Обрабатываем каждый файл\n",
    "    for mp4_file in mp4_files:\n",
    "        video_path = os.path.join(folder_path, mp4_file)\n",
    "        video_name = os.path.splitext(mp4_file)[0]  # Убираем расширение\n",
    "        process_video(video_path, SAVE_PATH, video_name)\n",
    "\n",
    "\n",
    "# Обработка видео\n",
    "def process_video(video_path, SAVE_PATH, video_name):\n",
    "    # Создание папки с именем видео, если ее еще нет\n",
    "    video_folder_path = os.path.join(SAVE_PATH, video_name)\n",
    "    if not os.path.exists(video_folder_path):\n",
    "        os.mkdir(video_folder_path)\n",
    "    \n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    frame_count = 0\n",
    "    nas_conf = 0.3\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        frame_count += 1\n",
    "        \n",
    "        if frame_count % fps != 0:\n",
    "            continue\n",
    "\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        # Предсказания для каждой модели\n",
    "        results_pose = yolo_pose.predict(frame)\n",
    "        results_nas = yolo_nas.predict(frame, conf=nas_conf, iou=0.8)\n",
    "        \n",
    "        # Получение bounding box'ов для телефонов\n",
    "        all_phone_bboxes = []\n",
    "        for res in results_nas:\n",
    "            bboxes = res.prediction.bboxes_xyxy\n",
    "            labels = res.prediction.labels\n",
    "            confidences = res.prediction.confidence\n",
    "            class_names = res.class_names\n",
    "\n",
    "            for i, (bbox, label, confidence) in enumerate(zip(bboxes, labels, confidences)):\n",
    "                if class_names[label.astype(int)]:\n",
    "                    bbox_width = bbox[2] - bbox[0]\n",
    "                    bbox_height = bbox[3] - bbox[1]\n",
    "    \n",
    "                    if confidence >= nas_conf and bbox_width < frame.shape[1] / 15 and bbox_height < frame.shape[0] / 15:\n",
    "                        all_phone_bboxes.append((bbox, confidence))\n",
    "\n",
    "        phone_detected = False\n",
    "        # Если bbox телефонов найдены, рассчитываем их центры\n",
    "        for phone_bbox, confidence in all_phone_bboxes:\n",
    "            # cv2.rectangle(frame, (int(phone_bbox[0]), int(phone_bbox[1])), (int(phone_bbox[2]), int(phone_bbox[3])), (255, 0, 0), 2)\n",
    "            # cv2.putText(frame, f\"{confidence:.2f}\", (int(phone_bbox[0]), int(phone_bbox[1]) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n",
    "            center_phone = [(phone_bbox[0] + phone_bbox[2]) / 2, (phone_bbox[1] + phone_bbox[3]) / 2]\n",
    "\n",
    "            # Получаем ключевые точки для всех обнаруженных объектов\n",
    "            keypoints = results_pose[0].keypoints.xy\n",
    "\n",
    "            # Для каждого обнаруженного объекта\n",
    "            for person_keypoints in keypoints:\n",
    "                wrists = []  # список для хранения координат обеих кистей\n",
    "                colors = [(128, 0, 128), (0, 255, 255)]  # фиолетовый и жёлтый цвета для визуализации\n",
    "\n",
    "                # Вытаскиваем ключевые точки для рук\n",
    "                for idx in [10, 9]:  # индексы для правого и левого запястья\n",
    "                    try:\n",
    "                        wrist = person_keypoints[idx].cpu().numpy()\n",
    "                        wrists.append(wrist)\n",
    "                    except:\n",
    "                        wrists.append(None)\n",
    "\n",
    "                # Визуализируем ключевые точки на кистях\n",
    "                for wrist, color in zip(wrists, colors):\n",
    "                    if wrist is not None:\n",
    "                        cv2.circle(frame, (int(wrist[0]), int(wrist[1])), 10, color, -1)\n",
    "\n",
    "                # Проверяем расстояние от каждой из этих точек до центра бокса телефона\n",
    "                for wrist in wrists:\n",
    "                    if wrist is not None:\n",
    "                        distance = np.linalg.norm(np.array(center_phone) - np.array(wrist))\n",
    "                        if distance < THRESHOLD:\n",
    "                            phone_detected = True\n",
    "                            break  # Если нашли одну точку руки рядом с телефоном, прерываем цикл\n",
    "\n",
    "            if phone_detected:\n",
    "                break\n",
    "\n",
    "        if phone_detected:\n",
    "            print(f\"Телефон в руке на кадре_{seconds_to_time(frame_count/fps)}\")\n",
    "            save_path = os.path.join(video_folder_path, f\"{seconds_to_time(frame_count/fps)}.jpg\")\n",
    "            cv2.imwrite(save_path, frame)\n",
    "\n",
    "    cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"/home/student/snap/code/Hackathons/Haborovsk/Анализ бригад (телефон)/Есть телефон\"\n",
    "SAVE_PATH = \"/home/student/snap/code/Hackathons/Haborovsk/Анализ бригад (телефон)/img_with_phones\"\n",
    "if not os.path.exists(SAVE_PATH):\n",
    "    os.mkdir(SAVE_PATH)\n",
    "\n",
    "video_name = \"00_26_30\"\n",
    "process_video(f\"/home/student/snap/code/Hackathons/Haborovsk/Анализ бригад (телефон)/Есть телефон/{video_name}.mp4\", SAVE_PATH, video_name)\n",
    "#process_all_videos_in_folder(folder_path, SAVE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"/home/student/snap/code/Hackathons/Haborovsk/Анализ бригад (телефон)/Есть телефон\"\n",
    "SAVE_PATH = \"/home/student/snap/code/Hackathons/Haborovsk/Анализ бригад (телефон)/img_with_phones\"\n",
    "process_all_videos_in_folder(folder_path, SAVE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EfficientDet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "# 1. Инициализация моделей\n",
    "device = torch.device(\"cuda:0\")  # для использования первой GPU\n",
    "model_url = \"https://tfhub.dev/tensorflow/efficientdet/d6/1\"\n",
    "tfmodel = hub.load(model_url)\n",
    "yolo_pose = YOLO('yolov8s-pose.pt')\n",
    "\n",
    "# Параметры\n",
    "THRESHOLD = 100  # Евклидово расстояние для определения близости\n",
    "frames_with_phone = set()\n",
    "\n",
    "def seconds_to_time(seconds):\n",
    "    minutes, seconds = divmod(seconds, 60)\n",
    "    minutes, seconds = int(minutes), int(seconds)\n",
    "    if minutes < 10:\n",
    "        minutes = f\"0{minutes}\"\n",
    "    if seconds < 10:\n",
    "        seconds = f\"0{seconds}\"\n",
    "    return f\"{minutes}:{seconds}\"\n",
    "\n",
    "# 2. Обработка видео\n",
    "def process_video(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    frame_count = 0\n",
    "    fps *= 5\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        frame_count += 1\n",
    "        \n",
    "        # Пропускаем кадры, чтобы обрабатывать только раз в секунду\n",
    "        if frame_count % fps != 0:\n",
    "            continue\n",
    "        \n",
    "        print(frame_count, fps)\n",
    "\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Предсказания для каждой модели\n",
    "        results_pose = yolo_pose.predict(frame)\n",
    "        \n",
    "        input_tensor = tf.convert_to_tensor(frame)  # Convert the frame to a tensor\n",
    "        input_tensor = tf.expand_dims(input_tensor, axis=0)  # Add batch dimension\n",
    "\n",
    "        detections = tfmodel(input_tensor)  # Делаем предсказание с помощью EfficientDet\n",
    "\n",
    "        # Получение bounding box'ов для телефонов\n",
    "        phone_bboxes = []\n",
    "        boxes = detections[\"detection_boxes\"].numpy()[0]\n",
    "        scores = detections[\"detection_scores\"].numpy()[0]\n",
    "        class_ids = detections[\"detection_classes\"].numpy()[0]\n",
    "\n",
    "        height, width, _ = frame.shape\n",
    "\n",
    "        all_phone_bboxes = []\n",
    "        for i, class_id in enumerate(class_ids):\n",
    "            if class_id == 77:  # класс \"cell phone\" имеет ID 77 в COCO\n",
    "                # Масштабируем bounding boxes и конвертируем формат\n",
    "                y_min, x_min, y_max, x_max = boxes[i]\n",
    "                bbox = [x_min * width, y_min * height, x_max * width, y_max * height]\n",
    "                \n",
    "                confidence = scores[i]\n",
    "                all_phone_bboxes.append((bbox, confidence))\n",
    "                \n",
    "        phone_bboxes = [bbox for bbox, confidence in all_phone_bboxes if confidence >= 0.4]\n",
    "        \n",
    "        phone_detected = False\n",
    "        # Если bbox телефонов найдены, рассчитываем их центры\n",
    "        for phone_bbox in phone_bboxes:\n",
    "            cv2.rectangle(frame, (int(phone_bbox[0]), int(phone_bbox[1])), (int(phone_bbox[2]), int(phone_bbox[3])), (255, 0, 0), 2)\n",
    "            # ... (ваш остальной код)\n",
    "            center_phone = [(phone_bbox[0] + phone_bbox[2]) / 2, (phone_bbox[1] + phone_bbox[3]) / 2]\n",
    "            \n",
    "            # Получаем ключевые точки для всех обнаруженных объектов\n",
    "            keypoints = results_pose[0].keypoints.xy\n",
    "            \n",
    "            # Для каждого обнаруженного объекта\n",
    "            for person_keypoints in keypoints:\n",
    "                # Вытаскиваем ключевые точки для рук\n",
    "                try:\n",
    "                    right_wrist = person_keypoints[10].cpu().numpy()\n",
    "                except Exception as e:\n",
    "                    pass\n",
    "                try:\n",
    "                    left_wrist = person_keypoints[9].cpu().numpy()\n",
    "                except Exception as e:\n",
    "                    pass\n",
    "\n",
    "                # Визуализируем ключевые точки на кистях\n",
    "                cv2.circle(frame, (int(right_wrist[0]), int(right_wrist[1])), 10, (128, 0, 128), -1)  # фиолетовый\n",
    "                cv2.circle(frame, (int(left_wrist[0]), int(left_wrist[1])), 10, (0, 255, 255), -1)  # жёлтый\n",
    "                # Проверяем расстояние от каждой из этих точек до центра бокса телефона\n",
    "                for hand_point in [right_wrist, left_wrist]:\n",
    "                    distance = np.linalg.norm(np.array(center_phone) - np.array(hand_point))\n",
    "                    if distance < THRESHOLD:\n",
    "                        phone_detected = True\n",
    "                        break  # Если нашли одну точку руки рядом с телефоном, прерываем цикл\n",
    "                    \n",
    "            if phone_detected:\n",
    "                break\n",
    "\n",
    "        if phone_detected:\n",
    "            print(f\"Телефон в руке на кадре_{seconds_to_time(frame_count/12)}\")\n",
    "            frames_with_phone.add(frame_count)\n",
    "            save_path = os.path.join(SAVE_PATH, f\"{seconds_to_time(frame_count/12)}.jpg\")\n",
    "            cv2.imwrite(save_path, frame)\n",
    "\n",
    "    print(sorted(frames_with_phone))\n",
    "    cap.release()\n",
    "\n",
    "# Запускаем обработку\n",
    "mp4_name = \"00_26_30\"\n",
    "video_path = f\"/home/student/snap/code/Hackathons/Haborovsk/Анализ бригад (телефон)/Есть телефон/{mp4_name}.mp4\"\n",
    "# Папка для сохранения кадров\n",
    "SAVE_PATH = f\"/home/student/snap/code/Hackathons/Haborovsk/Анализ бригад (телефон)/img_with_phones/{mp4_name}\"  # Замените на ваш путь\n",
    "if not os.path.exists(SAVE_PATH):\n",
    "    os.mkdir(SAVE_PATH)\n",
    "process_video(video_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EfficientDet TFLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "# 1. Инициализация моделей\n",
    "device = torch.device(\"cuda:0\")  # для использования первой GPU\n",
    "model_url = \"https://tfhub.dev/tensorflow/efficientdet/d7/1\"\n",
    "tfmodel = hub.load(model_url)\n",
    "\n",
    "# Сохраните модель в формате SavedModel\n",
    "saved_model_path = \"tfhub_model\"\n",
    "tf.saved_model.save(tfmodel, saved_model_path)\n",
    "\n",
    "# Конвертируйте модель в TFLite с FP16 квантованием\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_path)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.target_spec.supported_types = [tf.float16]\n",
    "tflite_model_fp16 = converter.convert()\n",
    "\n",
    "# Используйте TFLite модель для инференса\n",
    "interpreter = tf.lite.Interpreter(model_content=tflite_model_fp16)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "yolo_pose = YOLO('yolov8s-pose.pt')\n",
    "\n",
    "# Параметры\n",
    "THRESHOLD = 100  # Евклидово расстояние для определения близости\n",
    "frames_with_phone = set()\n",
    "\n",
    "def seconds_to_time(seconds):\n",
    "    minutes, seconds = divmod(seconds, 60)\n",
    "    minutes, seconds = int(minutes), int(seconds)\n",
    "    if minutes < 10:\n",
    "        minutes = f\"0{minutes}\"\n",
    "    if seconds < 10:\n",
    "        seconds = f\"0{seconds}\"\n",
    "    return f\"{minutes}:{seconds}\"\n",
    "\n",
    "# 2. Обработка видео\n",
    "def process_video(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    frame_count = 0\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        frame_count += 1\n",
    "        \n",
    "        if frame_count % fps != 0:\n",
    "            continue\n",
    "\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Предсказания для каждой модели\n",
    "        results_pose = yolo_pose.predict(frame)\n",
    "        \n",
    "        input_tensor = tf.convert_to_tensor(frame)  # Convert the frame to a tensor\n",
    "        input_tensor = tf.expand_dims(input_tensor, axis=0)  # Add batch dimension\n",
    "        \n",
    "        input_details = interpreter.get_input_details()\n",
    "        output_details = interpreter.get_output_details()\n",
    "\n",
    "        interpreter.set_tensor(input_details[0]['index'], input_tensor.numpy())\n",
    "        interpreter.invoke()\n",
    "        detections = {\n",
    "            \"detection_boxes\": interpreter.get_tensor(output_details[0]['index']),\n",
    "            \"detection_scores\": interpreter.get_tensor(output_details[1]['index']),\n",
    "            \"detection_classes\": interpreter.get_tensor(output_details[2]['index'])\n",
    "        }\n",
    "\n",
    "        # Получение bounding box'ов для телефонов\n",
    "        phone_bboxes = []\n",
    "        boxes = detections[\"detection_boxes\"].numpy()[0]\n",
    "        scores = detections[\"detection_scores\"].numpy()[0]\n",
    "        class_ids = detections[\"detection_classes\"].numpy()[0]\n",
    "\n",
    "        height, width, _ = frame.shape\n",
    "\n",
    "        for i, class_id in enumerate(class_ids):\n",
    "            if class_id == 77 and scores[i] >= 0.1:  # класс \"cell phone\" имеет ID 77 в COCO\n",
    "                # Масштабируем bounding boxes и конвертируем формат\n",
    "                y_min, x_min, y_max, x_max = boxes[i]\n",
    "                bbox = [x_min * width, y_min * height, x_max * width, y_max * height]\n",
    "                \n",
    "                confidence = scores[i]\n",
    "                phone_bboxes.append(bbox)\n",
    "                cv2.putText(frame, f\"{confidence:.2f}\", (int(bbox[0]), int(bbox[1]) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n",
    "        \n",
    "        phone_detected = False\n",
    "        # Если bbox телефонов найдены, рассчитываем их центры\n",
    "        for phone_bbox in phone_bboxes:\n",
    "            cv2.rectangle(frame, (int(phone_bbox[0]), int(phone_bbox[1])), (int(phone_bbox[2]), int(phone_bbox[3])), (255, 0, 0), 2)\n",
    "            # ... (ваш остальной код)\n",
    "            center_phone = [(phone_bbox[0] + phone_bbox[2]) / 2, (phone_bbox[1] + phone_bbox[3]) / 2]\n",
    "            \n",
    "            # Получаем ключевые точки для всех обнаруженных объектов\n",
    "            keypoints = results_pose[0].keypoints.xy\n",
    "            \n",
    "            # Для каждого обнаруженного объекта\n",
    "            for person_keypoints in keypoints:\n",
    "                # Вытаскиваем ключевые точки для рук\n",
    "                try:\n",
    "                    right_wrist = person_keypoints[10].cpu().numpy()\n",
    "                except Exception as e:\n",
    "                    pass\n",
    "                try:\n",
    "                    left_wrist = person_keypoints[9].cpu().numpy()\n",
    "                except Exception as e:\n",
    "                    pass\n",
    "\n",
    "                # Визуализируем ключевые точки на кистях\n",
    "                cv2.circle(frame, (int(right_wrist[0]), int(right_wrist[1])), 10, (128, 0, 128), -1)  # фиолетовый\n",
    "                cv2.circle(frame, (int(left_wrist[0]), int(left_wrist[1])), 10, (0, 255, 255), -1)  # жёлтый\n",
    "                # Проверяем расстояние от каждой из этих точек до центра бокса телефона\n",
    "                for hand_point in [right_wrist, left_wrist]:\n",
    "                    distance = np.linalg.norm(np.array(center_phone) - np.array(hand_point))\n",
    "                    if distance < THRESHOLD:\n",
    "                        phone_detected = True\n",
    "                        break  # Если нашли одну точку руки рядом с телефоном, прерываем цикл\n",
    "                    \n",
    "            if phone_detected:\n",
    "                break\n",
    "\n",
    "        if phone_detected:\n",
    "            print(f\"Телефон в руке на кадре_{seconds_to_time(frame_count/12)}\")\n",
    "            frames_with_phone.add(frame_count)\n",
    "            save_path = os.path.join(SAVE_PATH, f\"{seconds_to_time(frame_count/12)}.jpg\")\n",
    "            cv2.imwrite(save_path, frame)\n",
    "\n",
    "    print(sorted(frames_with_phone))\n",
    "    cap.release()\n",
    "\n",
    "# Запускаем обработку\n",
    "mp4_name = \"00_26_30\"\n",
    "video_path = f\"/home/student/snap/code/Hackathons/Haborovsk/Анализ бригад (телефон)/Есть телефон/{mp4_name}.mp4\"\n",
    "# Папка для сохранения кадров\n",
    "SAVE_PATH = f\"/home/student/snap/code/Hackathons/Haborovsk/Анализ бригад (телефон)/img_with_phones/{mp4_name}\"  # Замените на ваш путь\n",
    "if not os.path.exists(SAVE_PATH):\n",
    "    os.mkdir(SAVE_PATH)\n",
    "process_video(video_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
